{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example classification analysis using ShinyLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By Erica Suh and Stephen Piccolo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to perform a benchmark comparison of classification algorithms across multiple datasets. We assume the reader has a moderate level of understanding of shell scripting and Python scripting. We also assume that the user's operating system is UNIX-based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Penn Machine Learning Benchmarks (PMLB) repository contains a large number of datasets that can be used to test machine-learning algorithms. We can access this repository using the Python module named `pmlb`, which can be installed via `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pmlb in /usr/local/lib/python3.7/site-packages (0.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from pmlb) (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/site-packages (from pandas->pmlb) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/site-packages (from pandas->pmlb) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/site-packages (from pandas->pmlb) (2013b0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas->pmlb) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#pip3 install --upgrade pip\n",
    "pip3 install pmlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we will fetch 10 biology-related datasets from PMLB. First, define a list that indicates the unique identifier for each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['analcatdata_aids', 'ann-thyroid']\n",
    "#            'breast-cancer',\n",
    "#            'dermatology',\n",
    "#            'diabetes',\n",
    "#            'hepatitis',\n",
    "#            'iris',\n",
    "#            'liver-disorder',\n",
    "#            'molecular-biology_promoters',\n",
    "#            'yeast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMLB's [GitHub repository](https://github.com/EpistasisLab/penn-ml-benchmarks) demonstrates how `pmlb` is used in Python scripts.\n",
    "\n",
    "ShinyLearner requires that input data files have exactly one feature named 'Class', which includes the class labels. So we must modify the PMLB data to meet this requirement. After modify the data, we save each dataframe to a a file with a [supported file extension](https://github.com/srp33/ShinyLearner/blob/master/InputFormats.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "new_directories = [\"./Demo_Datasets/\", \"./Demo_Results_Basic/\", \"./Demo_Results_ParamsOptimized/\"]\n",
    "for directory in new_directories:\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for data in datasets:\n",
    "    curr_data = fetch_data(data)\n",
    "    curr_data = curr_data.rename(columns={'target': 'Class'})  # Rename 'target' to 'Class'\n",
    "    curr_data.to_csv('./Demo_Datasets/{}.tsv'.format(data), sep='\\t', index=True)  # Save to a .tsv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a benchmark comparison of 10 classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this initial analysis, we will apply 10 different classification algorithms to the 10 datasets we have prepared. We will use Monte Carlo cross validation (with *no* hyperparameter optimization). To keep the execution time reasonable, we will only do 2 iterations of Monte Carlo cross validation.\n",
    "\n",
    "ShinyLearner is executed within a Docker container. The ShinyLearner [web application](http://bioapps.byu.edu/shinylearner/) enables us to more easily build commands for executing ShinyLearner within Docker at the command line. We used this tool to create a template command. Below we modify that template and execute ShinyLearner for each dataset. We also indicate that we want to one-hot encode (`--ohe`) and scale the data (`--scale`) and that we want to impute any missing values (`--impute`).\n",
    "\n",
    "(*This process takes several minutes to execute. You won't see any output until the analysis has completed.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************************\n",
      "Command that was executed for analysis on Mon Apr 29 11:51:14 MDT 2019:\n",
      "\n",
      "/UserScripts/classification_montecarlo --data /InputData/analcatdata_aids.tsv --description analcatdata_aids --iterations 2 --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/svm/default* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/earth/default* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/h2o.randomForest/default* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/decision_tree/default* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/logistic_regression/default* --classif-algo /AlgorithmScripts/Classification/arff/weka/HoeffdingTree/default* --classif-algo /AlgorithmScripts/Classification/arff/weka/MultilayerPerceptron/default* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/mlp/default* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/multilayer_perceptron/default* --classif-algo /AlgorithmScripts/Classification/arff/weka/SimpleLogistic/default* --output-dir /OutputData --ohe true --scale true --impute true --verbose false\n",
      "\n",
      "ShinyLearner version: 484\n",
      "***********************************************************************\n",
      "\n",
      "[2019-04-29 11:51:14] Parsing data...\n",
      "[2019-04-29 11:51:14] After filtering, data were available for 50 instances and 5 data points.\n",
      "[2019-04-29 11:51:14] Imputing missing data (where applicable)...\n",
      "[2019-04-29 11:51:15] One-hot encoding categorical data (where applicable)...\n",
      "[2019-04-29 11:51:15] Scaling numerical data (where applicable)...\n",
      "[2019-04-29 11:51:16] The following columns do not contain numerical values and will not be scaled:\n",
      "[2019-04-29 11:51:16] \t Class\n",
      "[2019-04-29 11:51:16] In the following columns, fewer than half are distinct values, so they will not be scaled:\n",
      "[2019-04-29 11:51:16] \t Class, Age, Race\n",
      "[2019-04-29 11:51:16] Scaling using the robust approach\n",
      "[2019-04-29 11:51:16] Saving scaled version of data to /tmp/tmp.X2L25U9Pyp/data.gz\n",
      "[2019-04-29 11:51:16] Starting classification...\n",
      "Progress: 0% #\r",
      "Progress: 5% ###\r",
      "Progress: 10% ######\r",
      "Progress: 15% ########\r",
      "Progress: 21% ###########\r",
      "Progress: 26% ##############\r",
      "Progress: 31% ################\r",
      "Progress: 36% ###################\r",
      "Progress: 42% ######################\r",
      "Progress: 47% ########################\r",
      "Progress: 52% ###########################\r",
      "Progress: 57% #############################\r",
      "Progress: 63% ################################\r",
      "Progress: 68% ###################################\r",
      "Progress: 73% #####################################\r",
      "Progress: 78% ########################################\r",
      "Progress: 84% ###########################################\r",
      "Progress: 89% #############################################\r",
      "Progress: 94% ################################################\r",
      "Progress: 100% ###################################################                                                          \n",
      "[2019-04-29 11:51:40] Calculating classification metrics...\n",
      "[2019-04-29 11:51:42] Preparing output files...\n",
      "[2019-04-29 11:51:42] Analysis completed!\n",
      "***********************************************************************\n",
      "Command that was executed for analysis on Mon Apr 29 11:51:44 MDT 2019:\n",
      "\n",
      "/UserScripts/classification_montecarlo --data /InputData/ann-thyroid.tsv --description ann-thyroid --iterations 2 --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/svm/default* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/earth/default* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/h2o.randomForest/default* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/decision_tree/default* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/logistic_regression/default* --classif-algo /AlgorithmScripts/Classification/arff/weka/HoeffdingTree/default* --classif-algo /AlgorithmScripts/Classification/arff/weka/MultilayerPerceptron/default* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/mlp/default* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/multilayer_perceptron/default* --classif-algo /AlgorithmScripts/Classification/arff/weka/SimpleLogistic/default* --output-dir /OutputData --ohe true --scale true --impute true --verbose false\n",
      "\n",
      "ShinyLearner version: 484\n",
      "***********************************************************************\n",
      "\n",
      "[2019-04-29 11:51:44] Parsing data...\n",
      "[2019-04-29 11:51:45] After filtering, data were available for 7200 instances and 22 data points.\n",
      "[2019-04-29 11:51:45] Imputing missing data (where applicable)...\n",
      "[2019-04-29 11:51:46] One-hot encoding categorical data (where applicable)...\n",
      "[2019-04-29 11:51:46] Scaling numerical data (where applicable)...\n",
      "[2019-04-29 11:51:47] The following columns do not contain numerical values and will not be scaled:\n",
      "[2019-04-29 11:51:47] \t Class\n",
      "[2019-04-29 11:51:47] In the following columns, fewer than half are distinct values, so they will not be scaled:\n",
      "[2019-04-29 11:51:47] \t A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, Class, A18, A1, A20, A19, A17, A21\n",
      "[2019-04-29 11:51:47] No columns to be scaled, no action was performed\n",
      "[2019-04-29 11:51:48] Starting classification...\n",
      "Progress: 0% #\r",
      "Progress: 5% ###\r",
      "Progress: 10% ######\r",
      "Progress: 15% ########\r",
      "Progress: 21% ###########\r",
      "Progress: 26% ##############\r",
      "Progress: 31% ################\r",
      "Progress: 36% ###################\r",
      "Progress: 42% ######################\r",
      "Progress: 47% ########################\r",
      "Progress: 52% ###########################\r",
      "Progress: 57% #############################\r",
      "Progress: 63% ################################\r",
      "Progress: 68% ###################################\r",
      "Progress: 73% #####################################\r",
      "Progress: 78% ########################################\r",
      "Progress: 84% ###########################################\r",
      "Progress: 89% #############################################\r",
      "Progress: 94% ################################################\r",
      "Progress: 100% ###################################################                                                          \n",
      "[2019-04-29 11:52:52] Calculating classification metrics...\n",
      "[2019-04-29 11:52:55] Preparing output files...\n",
      "[2019-04-29 11:52:56] Analysis completed!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "function runShinyLearner {\n",
    "  dataset_file_path=\"$1\"  \n",
    "  dataset_file_name=\"$(basename $dataset_file_path)\"\n",
    "  dataset_name=\"${dataset_file_name/\\.tsv/}\"\n",
    "  dataset_dir_path=\"$(pwd)/Demo_Results_Basic/$dataset_name\"\n",
    "  \n",
    "  mkdir -p \"$dataset_dir_path\"\n",
    "\n",
    "  docker run --rm \\\n",
    "    -v \"$(pwd)/Demo_Datasets\":/InputData \\\n",
    "    -v \"$dataset_dir_path\":/OutputData \\\n",
    "    --user $(id -u):$(id -g) \\\n",
    "    srp33/shinylearner:version48 \\\n",
    "    /UserScripts/classification_montecarlo \\\n",
    "      --data \"/InputData/$dataset_file_name\" \\\n",
    "      --description \"$dataset_name\" \\\n",
    "      --iterations 2 \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/svm/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/mlr/earth/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/mlr/h2o.randomForest/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/decision_tree/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/logistic_regression/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/arff/weka/HoeffdingTree/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/arff/weka/MultilayerPerceptron/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/mlr/mlp/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/multilayer_perceptron/default*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/arff/weka/SimpleLogistic/default*\" \\\n",
    "      --output-dir \"/OutputData\" \\\n",
    "      --ohe true \\\n",
    "      --scale true \\\n",
    "      --impute true \\\n",
    "      --verbose false\n",
    "}\n",
    "\n",
    "rm -rf Demo_Results_Basic\n",
    "\n",
    "for dataset_file_path in ./Demo_Datasets/*.tsv\n",
    "do\n",
    "  runShinyLearner \"$dataset_file_path\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the benchmark comparison with hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShinyLearner provides an option to optimize a classification algorithm's hyperparameters. To accomplish this, it uses nested cross validation. This process requires more computational time, but it often increases classification accuracy. In the code below, we execute the same 10 classification algorithms on the same 10 datasets. There are some differences in the code below compared to the code above:\n",
    "\n",
    "1. We store the output in `Demo_Results_ParamsOptimized` rather than `Demo_Results_Basic`.\n",
    "2. We use the `nestedclassification_montecarlo` user script rather than `classification_montecarlo`.\n",
    "3. The path specified for each classification algorithm ends with `*` rather than `default*`. This tells ShinyLearner to evaluate all hyperparameter combinations, not just default ones.\n",
    "4. We indicate that we want to use 2 \"outer\" iterations and 2 \"inner\" iterations. In the previous example, we executed 5 iterations of Monte Carlo cross validation. But this time, we will use 2 rounds of nested (\"inner\") cross validation to optimize hyperparameters.\n",
    "\n",
    "(*This process takes several minutes to execute...much longer than the previous example. You won't see any output until the analysis has completed.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************************\n",
      "Command that was executed for analysis on Mon Apr 29 11:55:42 MDT 2019:\n",
      "\n",
      "/UserScripts/nestedclassification_montecarlo --data /InputData/analcatdata_aids.tsv --description analcatdata_aids --outer-iterations 2 --inner-iterations 2 --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/svm/* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/earth/* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/h2o.randomForest/* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/decision_tree/* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/logistic_regression/* --classif-algo /AlgorithmScripts/Classification/arff/weka/HoeffdingTree/* --classif-algo /AlgorithmScripts/Classification/arff/weka/MultilayerPerceptron/* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/mlp/* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/multilayer_perceptron/* --classif-algo /AlgorithmScripts/Classification/arff/weka/SimpleLogistic/* --output-dir /OutputData --ohe true --scale true --impute true --verbose false\n",
      "\n",
      "ShinyLearner version: 484\n",
      "***********************************************************************\n",
      "\n",
      "[2019-04-29 11:55:42] Parsing data...\n",
      "[2019-04-29 11:55:42] After filtering, data were available for 50 instances and 5 data points.\n",
      "[2019-04-29 11:55:42] Imputing missing data (where applicable)...\n",
      "[2019-04-29 11:55:43] One-hot encoding categorical data (where applicable)...\n",
      "[2019-04-29 11:55:43] Scaling numerical data (where applicable)...\n",
      "[2019-04-29 11:55:44] The following columns do not contain numerical values and will not be scaled:\n",
      "[2019-04-29 11:55:44] \t Class\n",
      "[2019-04-29 11:55:44] In the following columns, fewer than half are distinct values, so they will not be scaled:\n",
      "[2019-04-29 11:55:44] \t Class, Age, Race\n",
      "[2019-04-29 11:55:44] Scaling using the robust approach\n",
      "[2019-04-29 11:55:44] Saving scaled version of data to /tmp/tmp.3GjTtd3EcO/data.gz\n",
      "[2019-04-29 11:55:44] Classifying for inner iterations...\n",
      "Progress: 0% #\r",
      "Progress: 1% #\r",
      "Progress: 2% ##\r",
      "Progress: 3% ##\r",
      "Progress: 4% ###\r",
      "Progress: 5% ###\r",
      "Progress: 6% ####\r",
      "Progress: 7% ####\r",
      "Progress: 8% #####\r",
      "Progress: 9% #####\r",
      "Progress: 10% ######\r",
      "Progress: 11% ######\r",
      "Progress: 12% #######\r",
      "Progress: 13% #######\r",
      "Progress: 14% ########\r",
      "Progress: 15% ########\r",
      "Progress: 16% #########\r",
      "Progress: 17% #########\r",
      "Progress: 18% ##########\r",
      "Progress: 19% ##########\r",
      "Progress: 20% ###########\r",
      "Progress: 21% ###########\r",
      "Progress: 22% ############\r",
      "Progress: 23% ############\r",
      "Progress: 24% #############\r",
      "Progress: 25% #############\r",
      "Progress: 26% ##############\r",
      "Progress: 27% ##############\r",
      "Progress: 28% ###############\r",
      "Progress: 29% ###############\r",
      "Progress: 30% ################\r",
      "Progress: 31% ################\r",
      "Progress: 32% #################\r",
      "Progress: 33% #################\r",
      "Progress: 34% ##################\r",
      "Progress: 35% ##################\r",
      "Progress: 36% ###################\r",
      "Progress: 37% ###################\r",
      "Progress: 38% ####################\r",
      "Progress: 39% ####################\r",
      "Progress: 40% #####################\r",
      "Progress: 41% #####################\r",
      "Progress: 42% ######################\r",
      "Progress: 43% ######################\r",
      "Progress: 44% #######################\r",
      "Progress: 45% #######################\r",
      "Progress: 46% ########################\r",
      "Progress: 47% ########################\r",
      "Progress: 48% #########################\r",
      "Progress: 49% #########################\r",
      "Progress: 50% ##########################\r",
      "Progress: 51% ##########################\r",
      "Progress: 52% ###########################\r",
      "Progress: 53% ###########################\r",
      "Progress: 54% ############################\r",
      "Progress: 55% ############################\r",
      "Progress: 56% #############################\r",
      "Progress: 57% #############################\r",
      "Progress: 58% ##############################\r",
      "Progress: 59% ##############################\r",
      "Progress: 60% ###############################\r",
      "Progress: 61% ###############################\r",
      "Progress: 62% ################################\r",
      "Progress: 63% ################################\r",
      "Progress: 64% #################################\r",
      "Progress: 65% #################################\r",
      "Progress: 66% ##################################\r",
      "Progress: 67% ##################################\r",
      "Progress: 68% ###################################\r",
      "Progress: 69% ###################################\r",
      "Progress: 70% ####################################\r",
      "Progress: 71% ####################################\r",
      "Progress: 72% #####################################\r",
      "Progress: 73% #####################################\r",
      "Progress: 74% ######################################\r",
      "Progress: 75% ######################################\r",
      "Progress: 76% #######################################\r",
      "Progress: 77% #######################################\r",
      "Progress: 78% ########################################\r",
      "Progress: 79% ########################################\r",
      "Progress: 80% #########################################\r",
      "Progress: 81% #########################################\r",
      "Progress: 82% ##########################################\r",
      "Progress: 83% ##########################################\r",
      "Progress: 84% ###########################################\r",
      "Progress: 85% ###########################################\r",
      "Progress: 86% ############################################\r",
      "Progress: 87% ############################################\r",
      "Progress: 88% #############################################\r",
      "Progress: 89% #############################################\r",
      "Progress: 90% ##############################################\r",
      "Progress: 91% ##############################################\r",
      "Progress: 92% ###############################################\r",
      "Progress: 93% ###############################################\r",
      "Progress: 95% ################################################\r",
      "Progress: 96% #################################################\r",
      "Progress: 97% #################################################\r",
      "Progress: 98% ##################################################\r",
      "Progress: 99% ##################################################\r",
      "Progress: 100% ###################################################                                                          \n",
      "[2019-04-29 12:17:33] Calculating classification metrics for inner iterations...\n",
      "[2019-04-29 12:17:43] Parsing inner classification results...\n",
      "[2019-04-29 12:17:43] Identifying best combination of algorithms...\n",
      "[2019-04-29 12:17:44] Classifying for outer iterations...\n",
      "Progress: 0% #\r",
      "Progress: 5% ###\r",
      "Progress: 10% ######\r",
      "Progress: 15% ########\r",
      "Progress: 21% ###########\r",
      "Progress: 26% ##############\r",
      "Progress: 31% ################\r",
      "Progress: 36% ###################\r",
      "Progress: 42% ######################\r",
      "Progress: 47% ########################\r",
      "Progress: 52% ###########################\r",
      "Progress: 57% #############################\r",
      "Progress: 63% ################################\r",
      "Progress: 68% ###################################\r",
      "Progress: 73% #####################################\r",
      "Progress: 78% ########################################\r",
      "Progress: 84% ###########################################\r",
      "Progress: 89% #############################################\r",
      "Progress: 94% ################################################\r",
      "Progress: 100% ###################################################                                                          \n",
      "[2019-04-29 12:18:11] Calculating classification metrics for outer iterations...\n",
      "[2019-04-29 12:18:13] Preparing output files...\n",
      "[2019-04-29 12:18:14] Analysis completed!\n",
      "***********************************************************************\n",
      "Command that was executed for analysis on Mon Apr 29 12:18:17 MDT 2019:\n",
      "\n",
      "/UserScripts/nestedclassification_montecarlo --data /InputData/ann-thyroid.tsv --description ann-thyroid --outer-iterations 2 --inner-iterations 2 --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/svm/* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/earth/* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/h2o.randomForest/* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/decision_tree/* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/logistic_regression/* --classif-algo /AlgorithmScripts/Classification/arff/weka/HoeffdingTree/* --classif-algo /AlgorithmScripts/Classification/arff/weka/MultilayerPerceptron/* --classif-algo /AlgorithmScripts/Classification/tsv/mlr/mlp/* --classif-algo /AlgorithmScripts/Classification/tsv/sklearn/multilayer_perceptron/* --classif-algo /AlgorithmScripts/Classification/arff/weka/SimpleLogistic/* --output-dir /OutputData --ohe true --scale true --impute true --verbose false\n",
      "\n",
      "ShinyLearner version: 484\n",
      "***********************************************************************\n",
      "\n",
      "[2019-04-29 12:18:17] Parsing data...\n",
      "[2019-04-29 12:18:18] After filtering, data were available for 7200 instances and 22 data points.\n",
      "[2019-04-29 12:18:18] Imputing missing data (where applicable)...\n",
      "[2019-04-29 12:18:19] One-hot encoding categorical data (where applicable)...\n",
      "[2019-04-29 12:18:20] Scaling numerical data (where applicable)...\n",
      "[2019-04-29 12:18:20] The following columns do not contain numerical values and will not be scaled:\n",
      "[2019-04-29 12:18:20] \t Class\n",
      "[2019-04-29 12:18:20] In the following columns, fewer than half are distinct values, so they will not be scaled:\n",
      "[2019-04-29 12:18:20] \t A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, Class, A18, A1, A20, A19, A17, A21\n",
      "[2019-04-29 12:18:20] No columns to be scaled, no action was performed\n",
      "[2019-04-29 12:18:22] Classifying for inner iterations...\n",
      "Progress: 0% #\r",
      "Progress: 1% #\r",
      "Progress: 2% ##\r",
      "Progress: 3% ##\r",
      "Progress: 4% ###\r",
      "Progress: 5% ###\r",
      "Progress: 6% ####\r",
      "Progress: 7% ####\r",
      "Progress: 8% #####\r",
      "Progress: 9% #####\r",
      "Progress: 10% ######\r",
      "Progress: 11% ######\r",
      "Progress: 12% #######\r",
      "Progress: 13% #######\r",
      "Progress: 14% ########\r",
      "Progress: 15% ########\r",
      "Progress: 16% #########\r",
      "Progress: 17% #########\r",
      "Progress: 18% ##########\r",
      "Progress: 19% ##########\r",
      "Progress: 20% ###########\r",
      "Progress: 21% ###########\r",
      "Progress: 22% ############\r",
      "Progress: 23% ############\r",
      "Progress: 24% #############\r",
      "Progress: 25% #############\r",
      "Progress: 26% ##############\r",
      "Progress: 27% ##############\r",
      "Progress: 28% ###############\r",
      "Progress: 29% ###############\r",
      "Progress: 30% ################\r",
      "Progress: 31% ################\r",
      "Progress: 32% #################\r",
      "Progress: 33% #################\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scripts/nestedclassification: line 59:   185 Killed                  java $(getJavaArgs) -jar shinylearner.jar ANALYSIS_DATA_FILE=$analysisDataFile EXPERIMENT_FILE=$tmpDir/ie2 DEBUG=$verbose OUTPUT_BENCHMARK_FILE_PATH=$tmpDir/icb OUTPUT_PREDICTIONS_FILE_PATH=$tmpDir/ip NUM_CORES=$numCores TEMP_DIR=$tmpDir 2> /dev/null\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "function runShinyLearner {\n",
    "  dataset_file_path=\"$1\"\n",
    "  \n",
    "  dataset_file_name=\"$(basename $dataset_file_path)\"\n",
    "  dataset_name=\"${dataset_file_name/\\.tsv/}\"\n",
    "\n",
    "  docker run --rm \\\n",
    "    -v \"$(pwd)/Demo_Datasets\":/InputData \\\n",
    "    -v \"$(pwd)/Demo_Results_ParamsOptimized/$dataset_name\":/OutputData \\\n",
    "    --user $(id -u):$(id -g) \\\n",
    "    srp33/shinylearner:version484 \\\n",
    "    /UserScripts/nestedclassification_montecarlo \\\n",
    "      --data \"/InputData/$dataset_file_name\" \\\n",
    "      --description \"$dataset_name\" \\\n",
    "      --outer-iterations 2 \\\n",
    "      --inner-iterations 2 \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/svm/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/mlr/earth/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/mlr/h2o.randomForest/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/decision_tree/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/logistic_regression/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/arff/weka/HoeffdingTree/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/arff/weka/MultilayerPerceptron/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/mlr/mlp/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/tsv/sklearn/multilayer_perceptron/*\" \\\n",
    "      --classif-algo \"/AlgorithmScripts/Classification/arff/weka/SimpleLogistic/*\" \\\n",
    "      --output-dir \"/OutputData\" \\\n",
    "      --ohe true \\\n",
    "      --scale true \\\n",
    "      --impute true \\\n",
    "      --verbose false\n",
    "}\n",
    "\n",
    "rm -rf Demo_Results_Basic\n",
    "\n",
    "for dataset_file_path in ./Demo_Datasets/*.tsv\n",
    "do\n",
    "  runShinyLearner \"$dataset_file_path\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf Demo_Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing and visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the document called `Demo_Analysis.Rmd`, which contains R code for analyzing and visualizing the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
