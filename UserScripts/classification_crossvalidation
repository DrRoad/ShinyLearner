#!/bin/bash

set -euo pipefail

source scripts/shared_functions
source scripts/first_param_check

dataFiles="$(python scripts/ParseArgs.py --data TRUE "$@")"
description="$(python scripts/ParseArgs.py --description TRUE $@)"
numIterations="$(python scripts/ParseArgs.py --iterations TRUE $@)"
numFolds="$(python scripts/ParseArgs.py --folds TRUE $@)"
classifAlgos="$(python scripts/ParseArgs.py --classif-algo TRUE "$@")"
outputDir="$(python scripts/ParseArgs.py --output-dir TRUE $@)"
verbose="$(python scripts/ParseArgs.py --verbose FALSE false $@)"
ohe="$(python scripts/ParseArgs.py --ohe FALSE true $@)"
tmpDir="$(python scripts/ParseArgs.py --temp-dir FALSE '' $@)"

checkParamParseOutput "$dataFiles"
checkParamParseOutput "$description"
checkParamParseOutput "$numIterations"
checkParamParseOutput "$numFolds"
checkParamParseOutput "$classifAlgos"
checkParamParseOutput "$outputDir"
checkParamParseOutput "$verbose"
checkParamParseOutput "$ohe"
checkParamParseOutput "$tmpDir"

mkdir -p $outputDir
outPredictionsFile="$outputDir/Predictions.tsv"
outMetricsFile="$outputDir/Metrics.tsv"
outBenchmarkFile="$outputDir/ElapsedTime.tsv"
outLogFile="$outputDir/Log.txt"

source scripts/print_args

function cleanup {
  rm -rf $tmpDir
}

cleanup
tmpDir="$(getTempDir "$tmpDir")"

trap cleanup INT TERM EXIT

validationType=crossvalidation
source scripts/setup

echo "Parsing data..."
analysisDataFile=$tmpDir/data.gz
java -Xmx${mem} -jar shinylearner.jar RAW_DATA_FILES="$dataFiles" ANALYSIS_DATA_FILE="$analysisDataFile" DEBUG=$verbose TEMP_DIR=$tmpDir 2>&1 | tee -a "$outLogFile"

if [[ "$ohe" == "true" ]]
then
  echo "One-hot encoding categorical data (where applicable)..."
  python scripts/OneHotEncode.py "$analysisDataFile"
fi

## Move some more stuff from scripts/classification into here?
##   Find stuff that is common between montecarlo and crossvalidation?
## And abstract this into a script that is shared between montecarlo and crossvalidation?

for iteration in $(seq 1 $numIterations)
do
  iterationOutDir=$tmpDir/$iteration
  mkdir -p $iterationOutDir

  echo
  echo "**************************************************************" | tee -a "$outLogFile"
  echo "Beginning analysis for cross-validation fold ${iteration}" | tee -a "$outLogFile"
  echo "**************************************************************" | tee -a "$outLogFile"

  scripts/classification "$analysisDataFile" "$description" "$numFolds" "$verbose" "$classifAlgos" "$iterationOutDir/outpreds" "$iterationOutDir/outmetrics" "$iterationOutDir/outbench" crossvalidation $iteration $ohe "$iterationOutDir" 2>&1 | tee -a "$outLogFile"
done

echo
echo "**************************************************************" | tee -a "$outLogFile"
echo "Finalizing analysis"
echo "**************************************************************" | tee -a "$outLogFile"
echo

echo "Combining results across cross-validation iterations..." | tee -a "$outLogFile"
python scripts/CombineCrossValidationIterations.py "$tmpDir/*/outpreds,$tmpDir/*/outmetrics,$tmpDir/*/outbench" "$tmpDir/outpreds,$tmpDir/outmetrics,$tmpDir/outbenchmark" 2>&1 | tee -a "$outLogFile"

sortCriteria="-k1,1 -k2,2n -k3,3n -k4"
sortFile $tmpDir/outpreds "$sortCriteria" "$outPredictionsFile"
sortFile $tmpDir/outmetrics "$sortCriteria" "$outMetricsFile"
sortFile $tmpDir/outbenchmark "$sortCriteria" "$outBenchmarkFile"

cleanup

source scripts/success_message
